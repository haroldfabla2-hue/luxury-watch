"""
Ejemplos de Uso - Agente 5: Optimizador de Performance
====================================================

Ejemplos prÃ¡cticos y casos de uso reales para el sistema de optimizaciÃ³n.
"""

import os
import sys
from pathlib import Path

# Importar el agente
from agent_5_optimizador_performance import AutoOptimizer, GLTFPerformanceOptimizer

def ejemplo_optimizacion_basica():
    """Ejemplo 1: OptimizaciÃ³n bÃ¡sica con configuraciÃ³n por defecto"""
    print("\n" + "="*50)
    print("EJEMPLO 1: OPTIMIZACIÃ“N BÃSICA")
    print("="*50)
    
    # Crear optimizador automÃ¡tico
    optimizer = AutoOptimizer()
    
    # Archivos de ejemplo (reemplazar con rutas reales)
    input_file = "reloj_lujo.gltf"
    output_dir = "optimizado_basico"
    
    print(f"ğŸ”„ Optimizando: {input_file}")
    print(f"ğŸ“ Salida: {output_dir}")
    
    # Verificar que el archivo existe
    if not os.path.exists(input_file):
        print(f"âš ï¸ Archivo no encontrado: {input_file}")
        print("ğŸ’¡ Coloca un archivo .gltf en el directorio actual")
        return
    
    # Optimizar
    results = optimizer.auto_optimize(
        input_path=input_file,
        output_dir=output_dir,
        auto_detect_device=True
    )
    
    # Mostrar resultados
    print(f"\nâœ… OptimizaciÃ³n completada:")
    for device, stats in results['results_by_device'].items():
        reduction = stats.total_reduction_percent
        load_time = stats.estimated_load_mobile_ms if device == 'mobile' else \
                   stats.estimated_load_tablet_ms if device == 'tablet' else \
                   stats.estimated_load_desktop_ms
        
        print(f"  ğŸ“± {device.capitalize()}: {reduction:.1f}% reducciÃ³n, {load_time}ms carga")
    
    print(f"\nğŸ“ Archivos guardados en: {output_dir}/")

def ejemplo_optimizacion_personalizada():
    """Ejemplo 2: OptimizaciÃ³n con configuraciÃ³n personalizada"""
    print("\n" + "="*50)
    print("EJEMPLO 2: OPTIMIZACIÃ“N PERSONALIZADA")
    print("="*50)
    
    # Crear optimizador con configuraciÃ³n personalizada
    config_path = "aggressive_config.json"
    optimizer = GLTFPerformanceOptimizer(config_path)
    
    input_file = "joyeria_compleja.gltf"
    output_dir = "optimizado_agresivo"
    
    print(f"ğŸ”„ Optimizando con configuraciÃ³n: {config_path}")
    print(f"ğŸ“ Entrada: {input_file}")
    print(f"ğŸ“ Salida: {output_dir}")
    
    # Optimizar para mÃ³vil (dispositivo mÃ¡s restrictivo)
    stats = optimizer.optimize_glTF(
        input_path=input_file,
        output_dir=output_dir,
        target_device="mobile"
    )
    
    print(f"\nğŸ“Š Resultados detallados:")
    print(f"  ğŸ“ TamaÃ±o original: {stats.original_size_mb:.2f} MB")
    print(f"  ğŸ“¦ TamaÃ±o optimizado: {stats.optimized_size_mb:.2f} MB")
    print(f"  ğŸ“‰ ReducciÃ³n total: {stats.total_reduction_percent:.1f}%")
    print(f"  ğŸ—ï¸ ReducciÃ³n geometrÃ­a: {stats.geometry_reduction_percent:.1f}%")
    print(f"  ğŸ–¼ï¸ ReducciÃ³n texturas: {stats.texture_reduction_percent:.1f}%")
    print(f"  â±ï¸ Tiempo de procesamiento: {stats.processing_time_seconds:.2f}s")
    print(f"  ğŸ“Š LODs generados: {stats.lod_levels_count}")
    print(f"  â±ï¸ Tiempo de carga estimado: {stats.estimated_load_mobile_ms}ms")

def ejemplo_procesamiento_lotes():
    """Ejemplo 3: Procesamiento por lotes con monitoreo"""
    print("\n" + "="*50)
    print("EJEMPLO 3: PROCESAMIENTO POR LOTES")
    print("="*50)
    
    from concurrent.futures import ThreadPoolExecutor
    import time
    
    # Directorio con mÃºltiples modelos
    input_dir = "modelos_entrada"
    output_dir = "modelos_optimizados"
    
    # Buscar archivos glTF
    input_path = Path(input_dir)
    if not input_path.exists():
        print(f"âš ï¸ Directorio no encontrado: {input_dir}")
        print("ğŸ’¡ Crea un directorio con archivos .gltf")
        return
    
    gltf_files = list(input_path.rglob("*.gltf")) + list(input_path.rglob("*.glb"))
    
    if not gltf_files:
        print(f"âš ï¸ No se encontraron archivos .gltf en: {input_dir}")
        return
    
    print(f"ğŸ“¦ Encontrados {len(gltf_files)} archivos para procesar")
    
    # Crear optimizador
    auto_optimizer = AutoOptimizer()
    
    # Procesamiento paralelo
    def process_file(gltf_file):
        """Procesa un solo archivo"""
        rel_path = gltf_file.relative_to(input_path)
        model_output_dir = Path(output_dir) / rel_path.parent / gltf_file.stem
        model_output_dir.mkdir(parents=True, exist_ok=True)
        
        start_time = time.time()
        results = auto_optimizer.auto_optimize(
            input_path=str(gltf_file),
            output_dir=str(model_output_dir),
            auto_detect_device=True
        )
        processing_time = time.time() - start_time
        
        # Calcular reducciÃ³n promedio
        avg_reduction = sum(
            stats.total_reduction_percent 
            for stats in results['results_by_device'].values()
        ) / len(results['results_by_device'])
        
        return {
            'file': gltf_file.name,
            'reduction': avg_reduction,
            'time': processing_time,
            'success': True
        }
    
    # Procesar con barra de progreso
    print(f"\nğŸ”„ Procesando {len(gltf_files)} archivos...")
    
    results = []
    start_total = time.time()
    
    # Procesar en paralelo (mÃ¡ximo 2 workers para evitar sobrecarga)
    with ThreadPoolExecutor(max_workers=2) as executor:
        futures = {executor.submit(process_file, file): file for file in gltf_files}
        
        for future in futures:
            try:
                result = future.result()
                results.append(result)
                print(f"  âœ… {result['file']}: {result['reduction']:.1f}% reducciÃ³n")
            except Exception as e:
                file_name = futures[future].name
                print(f"  âŒ {file_name}: Error - {e}")
                results.append({
                    'file': file_name,
                    'reduction': 0,
                    'time': 0,
                    'success': False
                })
    
    total_time = time.time() - start_total
    
    # EstadÃ­sticas finales
    successful = [r for r in results if r['success']]
    failed = [r for r in results if not r['success']]
    
    if successful:
        avg_reduction = sum(r['reduction'] for r in successful) / len(successful)
        max_reduction = max(r['reduction'] for r in successful)
        min_reduction = min(r['reduction'] for r in successful)
        
        print(f"\nğŸ“Š EstadÃ­sticas del procesamiento:")
        print(f"  âœ… Exitosos: {len(successful)}/{len(gltf_files)}")
        print(f"  ğŸ“‰ ReducciÃ³n promedio: {avg_reduction:.1f}%")
        print(f"  ğŸ“ˆ ReducciÃ³n mÃ¡xima: {max_reduction:.1f}%")
        print(f"  ğŸ“‰ ReducciÃ³n mÃ­nima: {min_reduction:.1f}%")
        print(f"  â±ï¸ Tiempo total: {total_time:.2f}s")
        print(f"  ğŸš€ Tiempo promedio: {total_time/len(gltf_files):.2f}s por archivo")
    
    print(f"\nğŸ“ Resultados guardados en: {output_dir}/")

def ejemplo_integracion_pipeline():
    """Ejemplo 4: IntegraciÃ³n en pipeline de construcciÃ³n"""
    print("\n" + "="*50)
    print("EJEMPLO 4: INTEGRACIÃ“N EN PIPELINE")
    print("="*50)
    
    def optimize_build_assets(source_dir="src/assets/3d", build_dir="dist/assets/3d"):
        """FunciÃ³n de ejemplo para integrar en pipeline de build"""
        print(f"ğŸ”„ Integrando optimizaciÃ³n en pipeline de build...")
        print(f"ğŸ“ Origen: {source_dir}")
        print(f"ğŸ“ Destino: {build_dir}")
        
        # Verificar directorios
        source_path = Path(source_dir)
        if not source_path.exists():
            print(f"âŒ Directorio fuente no encontrado: {source_dir}")
            return False
        
        # Crear directorio destino
        build_path = Path(build_dir)
        build_path.mkdir(parents=True, exist_ok=True)
        
        # Buscar archivos glTF
        gltf_files = list(source_path.rglob("*.gltf")) + list(source_path.rglob("*.glb"))
        
        if not gltf_files:
            print(f"â„¹ï¸ No se encontraron archivos .gltf en: {source_dir}")
            return True
        
        print(f"ğŸ“¦ Optimizando {len(gltf_files)} archivos...")
        
        # Optimizar cada archivo
        auto_optimizer = AutoOptimizer()
        optimized_count = 0
        
        for gltf_file in gltf_files:
            try:
                # Crear estructura de directorios relativa
                rel_path = gltf_file.relative_to(source_path)
                model_output_dir = build_path / rel_path.parent / gltf_file.stem
                model_output_dir.mkdir(parents=True, exist_ok=True)
                
                # Optimizar
                results = auto_optimizer.auto_optimize(
                    input_path=str(gltf_file),
                    output_dir=str(model_output_dir),
                    auto_detect_device=True
                )
                
                # Mostrar resultado
                avg_reduction = sum(
                    stats.total_reduction_percent 
                    for stats in results['results_by_device'].values()
                ) / len(results['results_by_device'])
                
                print(f"  âœ… {rel_path}: {avg_reduction:.1f}% reducciÃ³n")
                optimized_count += 1
                
            except Exception as e:
                print(f"  âŒ {rel_path}: Error - {e}")
        
        print(f"\nğŸ‰ Pipeline completado:")
        print(f"  ğŸ“¦ Archivos procesados: {optimized_count}/{len(gltf_files)}")
        print(f"  ğŸ“ Build optimizado en: {build_dir}")
        
        return optimized_count == len(gltf_files)
    
    # Ejecutar ejemplo de integraciÃ³n
    success = optimize_build_assets()
    if success:
        print("âœ… IntegraciÃ³n en pipeline exitosa")
    else:
        print("âš ï¸ Hubo errores en la integraciÃ³n")

def ejemplo_analisis_avanzado():
    """Ejemplo 5: AnÃ¡lisis avanzado y optimizaciÃ³n por complejidad"""
    print("\n" + "="*50)
    print("EJEMPLO 5: ANÃLISIS AVANZADO")
    print("="*50)
    
    def smart_optimize_model(input_path: str, output_dir: str):
        """OptimizaciÃ³n inteligente basada en anÃ¡lisis de complejidad"""
        print(f"ğŸ” AnÃ¡lisis inteligente de: {input_path}")
        
        # Crear optimizador para anÃ¡lisis
        auto_optimizer = AutoOptimizer()
        
        # Analizar complejidad
        complexity = auto_optimizer._analyze_model_complexity(input_path)
        
        print(f"\nğŸ“Š AnÃ¡lisis de complejidad:")
        print(f"  ğŸ“ Score: {complexity['complexity_score']}/100")
        print(f"  ğŸ”¢ Meshes: {complexity['mesh_count']}")
        print(f"  ğŸ–¼ï¸ Texturas: {complexity['texture_count']}")
        print(f"  ğŸ’¾ TamaÃ±o texturas: {complexity['texture_size_mb']:.2f} MB")
        print(f"  ğŸ—ï¸ VÃ©rtices: {complexity['vertex_count']:,}")
        
        # Determinar estrategia Ã³ptima
        strategy = auto_optimizer._determine_optimization_strategy(complexity)
        device = auto_optimizer._detect_primary_device(complexity)
        
        print(f"\nğŸ¯ Estrategia Ã³ptima:")
        print(f"  ğŸ“‹ Estrategia: {strategy['strategy']}")
        print(f"  ğŸ“ DescripciÃ³n: {strategy['description']}")
        print(f"  ğŸ“± Dispositivo principal: {device}")
        print(f"  ğŸ“Š LODs: {strategy['recommended_lod_levels']}")
        print(f"  ğŸ¨ Calidad texturas: {strategy['recommended_texture_quality']:.2f}")
        
        # Seleccionar configuraciÃ³n segÃºn complejidad
        if complexity['complexity_score'] < 30:
            config = "light_config.json"
            strategy_name = "light"
        elif complexity['complexity_score'] < 70:
            config = "balanced_config.json" 
            strategy_name = "balanced"
        else:
            config = "aggressive_config.json"
            strategy_name = "aggressive"
        
        print(f"\nğŸ”§ ConfiguraciÃ³n seleccionada: {config}")
        
        # Optimizar con configuraciÃ³n seleccionada
        if not os.path.exists(config):
            print(f"âš ï¸ ConfiguraciÃ³n no encontrada, usando default")
            config = "config.json"
        
        optimizer = GLTFPerformanceOptimizer(config)
        
        start_time = time.time()
        stats = optimizer.optimize_glTF(
            input_path=input_path,
            output_dir=output_dir,
            target_device=device
        )
        processing_time = time.time() - start_time
        
        print(f"\nâœ… OptimizaciÃ³n {strategy_name} completada:")
        print(f"  ğŸ“‰ ReducciÃ³n: {stats.total_reduction_percent:.1f}%")
        print(f"  ğŸ–¼ï¸ ReducciÃ³n texturas: {stats.texture_reduction_percent:.1f}%")
        print(f"  ğŸ—ï¸ ReducciÃ³n geometrÃ­a: {stats.geometry_reduction_percent:.1f}%")
        print(f"  â±ï¸ Tiempo: {processing_time:.2f}s")
        print(f"  ğŸ“± Optimizado para: {device}")
        
        return stats
    
    # Ejecutar anÃ¡lisis y optimizaciÃ³n inteligente
    input_file = "modelo_complejo.gltf"
    
    if os.path.exists(input_file):
        stats = smart_optimize_model(input_file, "smart_optimized")
    else:
        print(f"âš ï¸ Archivo no encontrado: {input_file}")
        print("ğŸ’¡ Coloca un archivo .gltf en el directorio actual")

def ejemplo_monitoreo_performance():
    """Ejemplo 6: Monitoreo de performance en tiempo real"""
    print("\n" + "="*50)
    print("EJEMPLO 6: MONITOREO DE PERFORMANCE")
    print("="*50)
    
    import time
    import threading
    import psutil
    import os
    
    def monitor_system():
        """Monitor del sistema durante optimizaciÃ³n"""
        process = psutil.Process(os.getpid())
        
        while monitor_system.running:
            cpu_percent = process.cpu_percent()
            memory_mb = process.memory_info().rss / 1024 / 1024
            
            print(f"ğŸ“Š Sistema: CPU {cpu_percent:.1f}% | RAM {memory_mb:.1f}MB", end='\r')
            time.sleep(1)
    
    def optimize_with_monitoring(input_path: str, output_dir: str):
        """OptimizaciÃ³n con monitoreo del sistema"""
        print(f"ğŸ”„ Optimizando con monitoreo: {input_path}")
        
        # Iniciar monitoreo
        monitor_system.running = True
        monitor_thread = threading.Thread(target=monitor_system)
        monitor_thread.daemon = True
        monitor_thread.start()
        
        try:
            # Optimizar
            auto_optimizer = AutoOptimizer()
            results = auto_optimizer.auto_optimize(
                input_path=input_path,
                output_dir=output_dir,
                auto_detect_device=True
            )
            
            # Mostrar estadÃ­sticas finales
            total_time = results['total_processing_time']
            
            print(f"\nâœ… OptimizaciÃ³n completada en {total_time:.2f}s")
            
            for device, stats in results['results_by_device'].items():
                print(f"  ğŸ“± {device}: {stats.total_reduction_percent:.1f}% reducciÃ³n")
                
        finally:
            # Detener monitoreo
            monitor_system.running = False
            print(f"\nğŸ“Š Monitoreo detenido")
    
    # Archivo de ejemplo
    input_file = "watch_premium.gltf"
    
    if os.path.exists(input_file):
        optimize_with_monitoring(input_file, "monitored_output")
    else:
        print(f"âš ï¸ Archivo no encontrado: {input_file}")
        print("ğŸ’¡ Coloca un archivo .gltf en el directorio actual")

def ejecutar_todos_los_ejemplos():
    """Ejecuta todos los ejemplos en secuencia"""
    print("ğŸš€ EJECUTANDO TODOS LOS EJEMPLOS")
    print("=" * 60)
    
    ejemplos = [
        ("OptimizaciÃ³n BÃ¡sica", ejemplo_optimizacion_basica),
        ("OptimizaciÃ³n Personalizada", ejemplo_optimizacion_personalizada),
        ("Procesamiento por Lotes", ejemplo_procesamiento_lotes),
        ("IntegraciÃ³n en Pipeline", ejemplo_integracion_pipeline),
        ("AnÃ¡lisis Avanzado", ejemplo_analisis_avanzado),
        ("Monitoreo de Performance", ejemplo_monitoreo_performance)
    ]
    
    for nombre, funcion in ejemplos:
        try:
            print(f"\nğŸ¬ Ejecutando: {nombre}")
            funcion()
            print(f"âœ… {nombre} completado")
        except KeyboardInterrupt:
            print(f"\nâ¹ï¸ Ejemplos interrumpidos por el usuario")
            break
        except Exception as e:
            print(f"âŒ Error en {nombre}: {e}")
            import traceback
            traceback.print_exc()
    
    print(f"\nğŸ‰ Todos los ejemplos completados")

if __name__ == "__main__":
    print("ğŸ“š EJEMPLOS DE USO - AGENTE 5: OPTIMIZADOR DE PERFORMANCE")
    print("=" * 70)
    
    # Mostrar menÃº de ejemplos
    ejemplos = {
        "1": ("OptimizaciÃ³n BÃ¡sica", ejemplo_optimizacion_basica),
        "2": ("OptimizaciÃ³n Personalizada", ejemplo_optimizacion_personalizada),
        "3": ("Procesamiento por Lotes", ejemplo_procesamiento_lotes),
        "4": ("IntegraciÃ³n en Pipeline", ejemplo_integracion_pipeline),
        "5": ("AnÃ¡lisis Avanzado", ejemplo_analisis_avanzado),
        "6": ("Monitoreo de Performance", ejemplo_monitoreo_performance),
        "0": ("Ejecutar Todos", ejecutar_todos_los_ejemplos)
    }
    
    print("\nEjemplos disponibles:")
    for key, (nombre, _) in ejemplos.items():
        print(f"  {key}. {nombre}")
    
    try:
        choice = input(f"\nğŸ”¢ Selecciona un ejemplo (0-{len(ejemplos)-1}): ").strip()
        
        if choice in ejemplos:
            nombre, funcion = ejemplos[choice]
            print(f"\nğŸ¬ Ejecutando: {nombre}")
            funcion()
        else:
            print("âŒ OpciÃ³n invÃ¡lida")
            
    except KeyboardInterrupt:
        print(f"\nğŸ‘‹ Ejemplos cancelados por el usuario")
    except Exception as e:
        print(f"\nâŒ Error: {e}")